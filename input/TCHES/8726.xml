<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/  http://www.openarchives.org/OAI/2.0/oai_dc.xsd"><id>8726</id>
	<dc:title xml:lang="en-US">Ranking Loss: Maximizing the Success Rate in Deep Learning Side-Channel Analysis</dc:title>
	<dc:creator>Zaid, Gabriel</dc:creator>
	<dc:creator>Bossuet, Lilian</dc:creator>
	<dc:creator>Dassance, François</dc:creator>
	<dc:creator>Habrard, Amaury</dc:creator>
	<dc:creator>Venelli, Alexandre</dc:creator>
	<dc:subject xml:lang="en-US">Side-Channel Attacks</dc:subject>
	<dc:subject xml:lang="en-US">Deep Learning</dc:subject>
	<dc:subject xml:lang="en-US">Learning to Rank</dc:subject>
	<dc:subject xml:lang="en-US">Loss function</dc:subject>
	<dc:subject xml:lang="en-US">Success Rate</dc:subject>
	<dc:subject xml:lang="en-US">Mutual Information</dc:subject>
	<dc:description xml:lang="en-US">The side-channel community recently investigated a new approach, based on deep learning, to significantly improve profiled attacks against embedded systems. Compared to template attacks, deep learning techniques can deal with protected implementations, such as masking or desynchronization, without substantial preprocessing. However, important issues are still open. One challenging problem is to adapt the methods classically used in the machine learning field (e.g. loss function, performance metrics) to the specific side-channel context in order to obtain optimal results. We propose a new loss function derived from the learning to rank approach that helps preventing approximation and estimation errors, induced by the classical cross-entropy loss. We theoretically demonstrate that this new function, called Ranking Loss (RkL), maximizes the success rate by minimizing the ranking error of the secret key in comparison with all other hypotheses. The resulting model converges towards the optimal distinguisher when considering the mutual information between the secret and the leakage. Consequently, the approximation error is prevented. Furthermore, the estimation error, induced by the cross-entropy, is reduced by up to 23%. When the ranking loss is used, the convergence towards the best solution is up to 23% faster than a model using the cross-entropy loss function. We validate our theoretical propositions on public datasets.</dc:description>
	<dc:publisher xml:lang="en-US">Ruhr-Universität Bochum</dc:publisher>
	<dc:date>2020-12-03</dc:date>
	<dc:type>info:eu-repo/semantics/article</dc:type>
	<dc:type>info:eu-repo/semantics/publishedVersion</dc:type>
	<dc:format>application/pdf</dc:format>
	<dc:identifier>https://tches.iacr.org/index.php/TCHES/article/view/8726</dc:identifier>
	<dc:identifier>10.46586/tches.v2021.i1.25-55</dc:identifier>
	<dc:source xml:lang="en-US">IACR Transactions on Cryptographic Hardware and Embedded Systems; Volume 2021, Issue 1; 25-55</dc:source>
	<dc:source>2569-2925</dc:source>
	<dc:language>eng</dc:language>
	<dc:relation>https://tches.iacr.org/index.php/TCHES/article/view/8726/8326</dc:relation>
	<dc:rights xml:lang="en-US">Copyright (c) 2020 Gabriel Zaid, Lilian Bossuet, François Dassance, Amaury Habrard, Alexandre Venelli</dc:rights>
	<dc:rights xml:lang="en-US">https://creativecommons.org/licenses/by/4.0/</dc:rights>
</oai_dc:dc>