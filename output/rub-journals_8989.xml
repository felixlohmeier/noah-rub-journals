<mets:mets xmlns:mets="http://www.loc.gov/METS/" xmlns:mods="http://www.loc.gov/mods/v3" xmlns:xlink="http://www.w3.org/1999/xlink">
    <mets:dmdSec ID="DMD_rub-journals_8989">
        <mets:mdWrap MIMETYPE="text/xml" MDTYPE="MODS">
            <mets:xmlData>
                <mods xmlns="http://www.loc.gov/mods/v3" version="3.7" xmlns:vl="http://visuallibrary.net/vl">
                    <titleInfo lang="eng">
                        <title>Reinforcement Learning for Hyperparameter Tuning in Deep Learning-based Side-channel Analysis</title>
                    </titleInfo>
                    <name type="personal">
                        <displayForm>Rijsdijk, Jorai</displayForm>
                        <namePart type="family">Rijsdijk</namePart>
                        <namePart type="given">Jorai</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">ctb</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <displayForm>Wu, Lichao</displayForm>
                        <namePart type="family">Wu</namePart>
                        <namePart type="given">Lichao</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">ctb</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <displayForm>Perin, Guilherme</displayForm>
                        <namePart type="family">Perin</namePart>
                        <namePart type="given">Guilherme</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">ctb</roleTerm>
                        </role>
                    </name>
                    <name type="personal">
                        <displayForm>Picek, Stjepan</displayForm>
                        <namePart type="family">Picek</namePart>
                        <namePart type="given">Stjepan</namePart>
                        <role>
                            <roleTerm type="code" authority="marcrelator">ctb</roleTerm>
                        </role>
                    </name>
                    <typeOfResource>text</typeOfResource>
                    <genre authority="dini">article</genre>
                    <originInfo>
                        <dateIssued encoding="w3cdtf" keyDate="yes">2021-07-09</dateIssued>
                    </originInfo>
                    <language>
                        <languageTerm type="code" authority="iso639-2b">eng</languageTerm>
                    </language>
                    <physicalDescription>
                        <extent unit="page">31</extent>
                    </physicalDescription>
                    <abstract lang="eng">Deep learning represents a powerful set of techniques for profiling sidechannel analysis. The results in the last few years show that neural network architectures like multilayer perceptron and convolutional neural networks give strong attack performance where it is possible to break targets protected with various countermeasures. Considering that deep learning techniques commonly have a plethora of hyperparameters to tune, it is clear that such top attack results can come with a high price in preparing the attack. This is especially problematic as the side-channel community commonly uses random search or grid search techniques to look for the best hyperparameters.In this paper, we propose to use reinforcement learning to tune the convolutional neural network hyperparameters. In our framework, we investigate the Q-Learning paradigm and develop two reward functions that use side-channel metrics. We mount an investigation on three commonly used datasets and two leakage models where the results show that reinforcement learning can find convolutional neural networks exhibiting top performance while having small numbers of trainable parameters. We note that our approach is automated and can be easily adapted to different datasets. Several of our newly developed architectures outperform the current state-of-the-art results. Finally, we make our source code publicly available.
https://github.com/AISyLab/Reinforcement-Learning-for-SCA</abstract>
                    <subject lang="ger">
                    </subject>
                    <subject lang="eng">
First argument to forEach is not an array or JSON objectFirst argument to forEach is not an array or JSON objectFirst argument to forEach is not an array or JSON objectFirst argument to forEach is not an array or JSON objectFirst argument to forEach is not an array or JSON objectFirst argument to forEach is not an array or JSON objectFirst argument to forEach is not an array or JSON object                    </subject>
                    <identifier type="doi">10.46586/tches.v2021.i3.677-707</identifier>
                    <accessCondition type="use and reproduction" xlink:href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</accessCondition>
                    <recordInfo>
                        <recordIdentifier>rub-journals_8989</recordIdentifier>
                    </recordInfo>
                    <extension>
                        <vl:doctype>oaArticle</vl:doctype>
                    </extension>
                </mods>
            </mets:xmlData>
        </mets:mdWrap>
    </mets:dmdSec>
    <mets:fileSec>
        <mets:fileGrp USE="pdf upload">
            <mets:file MIMETYPE="application/pdf" ID="FILE0_rub-journals_8989">
                <mets:FLocat xlink:href="https://tches.iacr.org/index.php/TCHES/article/download/8989/8566" LOCTYPE="URL"/>
            </mets:file>
        </mets:fileGrp>
    </mets:fileSec>
    <mets:structMap TYPE="LOGICAL">
        <mets:div TYPE="document" ID="rub-journals_8989" DMDID="DMD_rub-journals_8989">
            <mets:fptr FILEID="FILE0_rub-journals_8989"/>
        </mets:div>
    </mets:structMap>
</mets:mets>
